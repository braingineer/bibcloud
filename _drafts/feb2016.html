---
title: february paper stack 2016
layout: main
categories: bibs
date: 2016-02-29
---




<blockquote><p>on-stack papers for february 2016</p></blockquote>

<div id='bibitems'><div class='btn-container'><br><input class='search' placeholder='Search title, authors, abstract, and notes'/><br><button class='sort' data-sort='author'>Sort by Author</button><button class='sort' data-sort='year'>Sort by Year</button><button class='sort' data-sort='title'>Sort by Title</button><button id='showhide'>Expand all annotations</button></div>
<ul class='bib list'><li>
                  <div id='entry0' class='bib entry'>

                    <a href='http://arxiv.org/abs/1409.0473' class='title'>Neural Machine Translation by Jointly Learning to Align and Translate</a>
                    <br><span class='author'>Dzmitry Bahdanau and
Kyunghyun Cho and
Yoshua Bengio.</span> <br>
                    <span class='year'>2014</span><br>
                    <div id='annotation0hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno0' class='bib annotation'>
                          <div id='abstract0' class='bib abstract'><b>Abstract</b>
                            Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.</div>
                          <div id='notes0' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry1' class='bib entry'>

                    <a href='http://arxiv.org/abs/1511.06388' class='title'>sense2vec-A Fast and Accurate Method for Word Sense Disambiguation In Neural Word Embeddings</a>
                    <br><span class='author'>Trask, Andrew and Michalak, Phil and Liu, John.</span> <br>
                    <span class='year'>2015</span><br>
                    <div id='annotation1hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno1' class='bib annotation'>
                          <div id='abstract1' class='bib abstract'><b>Abstract</b>
                            Neural word representations have proven useful in Natural Language Processing (NLP) tasks due to their ability to efficiently model complex semantic and syntactic word relationships. However, most techniques model only one representation per word, despite the fact that a single word can have multiple meanings or "senses". Some techniques model words by using multiple vectors that are clustered based on context. However, recent neural approaches rarely focus on the application to a consuming NLP algorithm. Furthermore, the training process of recent word-sense models is expensive relative to single-sense embedding processes. This paper presents a novel approach which addresses these concerns by modeling multiple embeddings for each word based on supervised disambiguation, which provides a fast and accurate way for a consuming NLP model to select a sense-disambiguated embedding. We demonstrate that these embeddings can disambiguate both contrastive senses such as nominal and verbal senses as well as nuanced senses such as sarcasm. We further evaluate Part-of-Speech disambiguated embeddings on neural dependency parsing, yielding a greater than 8% average error reduction in unlabeled attachment scores across 6 languages.</div>
                          <div id='notes1' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry2' class='bib entry'>

                    <a href='https://www.tensorflow.org/versions/r0.7/extras/candidate_sampling.pdf' class='title'>Candidate Sampling Algorithms in Tensorflow</a>
                    <br><span class='author'>Google.</span> <br>
                    <span class='year'>Empty</span><br>
                    <div id='annotation2hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno2' class='bib annotation'>
                          <div id='abstract2' class='bib abstract'><b>Abstract</b>
                            Empty</div>
                          <div id='notes2' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry3' class='bib entry'>

                    <a href='http://arxiv.org/abs/1511.02799' class='title'>Deep Compositional Question Answering with Neural Module Networks</a>
                    <br><span class='author'>Jacob Andreas and
Marcus Rohrbach and
Trevor Darrell and
Dan Klein.</span> <br>
                    <span class='year'>2015</span><br>
                    <div id='annotation3hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno3' class='bib annotation'>
                          <div id='abstract3' class='bib abstract'><b>Abstract</b>
                            Visual question answering is fundamentally compositional in nature---a question like "where is the dog?" shares substructure with questions like "what color is the dog?" and "where is the cat?" This paper seeks to simultaneously exploit the representational capacity of deep networks and the compositional linguistic structure of questions. We describe a procedure for constructing and learning *neural module networks*, which compose collections of jointly-trained neural "modules" into deep networks for question answering. Our approach decomposes questions into their linguistic substructures, and uses these structures to dynamically instantiate modular networks (with reusable components for recognizing dogs, classifying colors, etc.). The resulting compound networks are jointly trained. We evaluate our approach on two challenging datasets for visual question answering, achieving state-of-the-art results on both the VQA natural image dataset and a new dataset of complex questions about abstract shapes.</div>
                          <div id='notes3' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry4' class='bib entry'>

                    <a href='http://arxiv.org/pdf/1406.6247v1.pdf' class='title'>Recurrent models of visual attention</a>
                    <br><span class='author'>Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and others.</span> <br>
                    <span class='year'>2014</span><br>
                    <div id='annotation4hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno4' class='bib annotation'>
                          <div id='abstract4' class='bib abstract'><b>Abstract</b>
                            Applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels. We present a novel recurrent neural network model that is capable of extracting information from an image or video by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution. Like convolutional neural networks, the proposed model has a degree of translation invariance built-in, but the amount of computation it performs can be controlled independently of the input image size. While the model is non-differentiable, it can be trained using reinforcement learning methods to learn task-specific policies. We evaluate our model on several image classification tasks, where it significantly outperforms a convolutional neural network baseline on cluttered images, and on a dynamic visual control problem, where it learns to track a simple object without an explicit training signal for doing so.</div>
                          <div id='notes4' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry5' class='bib entry'>

                    <a href='http://nlp.stanford.edu/~socherr/SocherKarpathyLeManningNg_TACL2013.pdf' class='title'>Grounded compositional semantics for finding and describing images with sentences</a>
                    <br><span class='author'>Socher, Richard and Karpathy, Andrej and Le, Quoc V and Manning, Christopher D and Ng, Andrew Y.</span> <br>
                    <span class='year'>2014</span><br>
                    <div id='annotation5hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno5' class='bib annotation'>
                          <div id='abstract5' class='bib abstract'><b>Abstract</b>
                            Previous work on Recursive Neural Networks (RNNs) shows that these models can produce compositional feature vectors for accurately representing and classifying sentences or images. However, the sentence vectors of previous models cannot accurately represent visually grounded meaning. We introduce the DTRNN model which uses dependency trees to embed sentences into a vector space in order to retrieve images that are described by those sentences. Unlike previous RNN-based models which use constituency trees, DT-RNNs naturally focus on the action and agents in a sentence. They are better able to abstract from the details of word order and syntactic expression. DT-RNNs outperform other recursive and recurrent neural networks, kernelized CCA and a bag-of-words baseline on the tasks of finding an image that fits a sentence description and vice versa. They also give more similar representations to sentences that describe the same image.</div>
                          <div id='notes5' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry6' class='bib entry'>

                    <a href='http://arxiv.org/abs/1601.01280' class='title'>Language to Logical Form with Neural Attention</a>
                    <br><span class='author'>Dong, Li and Lapata, Mirella.</span> <br>
                    <span class='year'>2016</span><br>
                    <div id='annotation6hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno6' class='bib annotation'>
                          <div id='abstract6' class='bib abstract'><b>Abstract</b>
                            Semantic parsing aims at mapping natural language to machine interpretable meaning representations. Traditional approaches rely on high-quality lexicons, manually-built templates, and linguistic features which are either domain- or representation-specific. In this paper, we present a general method based on an attention-enhanced sequence-to-sequence model. We encode input sentences into vector representations using recurrent neural networks, and generate their logical forms by conditioning the output on the encoding vectors. The model is trained in an end-to-end fashion to maximize the likelihood of target logical forms given the natural language inputs. Experimental results on four datasets show that our approach performs competitively without using hand-engineered features and is easy to adapt across domains and meaning representations.</div>
                          <div id='notes6' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry7' class='bib entry'>

                    <a href='http://arxiv.org/abs/1503.00075' class='title'>Improved semantic representations from tree-structured long short-term memory networks</a>
                    <br><span class='author'>Tai, Kai Sheng and Socher, Richard and Manning, Christopher D.</span> <br>
                    <span class='year'>2015</span><br>
                    <div id='annotation7hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno7' class='bib annotation'>
                          <div id='abstract7' class='bib abstract'><b>Abstract</b>
                            Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank).</div>
                          <div id='notes7' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry8' class='bib entry'>

                    <a href='http://arxiv.org/abs/1511.00060' class='title'>Tree Recurrent Neural Networks with Application to Language Modeling</a>
                    <br><span class='author'>Xingxing Zhang and
Liang Lu and
Mirella Lapata.</span> <br>
                    <span class='year'>2015</span><br>
                    <div id='annotation8hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno8' class='bib annotation'>
                          <div id='abstract8' class='bib abstract'><b>Abstract</b>
                            Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have been successfully applied to a variety of sequence modeling tasks. In this paper we develop Tree Long Short-Term Memory (TreeLSTM), a neural network model based on LSTM, which is designed to predict a tree rather than a linear sequence. TreeLSTM defines the probability of a sentence by estimating the generation probability of its dependency tree. At each time step, a node is generated based on the representation of the generated sub-tree. We further enhance the modeling power of TreeLSTM by explicitly representing the correlations between left and right dependents. Application of our model to the MSR sentence completion challenge achieves results beyond the current state of the art. We also report results on dependency parsing reranking achieving competitive performance.</div>
                          <div id='notes8' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry9' class='bib entry'>

                    <a href='http://www.fit.vutbr.cz/~imikolov/rnnlm/google.pdf' class='title'>Statistical Language Models based on Neural Networks</a>
                    <br><span class='author'>Tomas Mikilov.</span> <br>
                    <span class='year'>2012</span><br>
                    <div id='annotation9hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno9' class='bib annotation'>
                          <div id='abstract9' class='bib abstract'><b>Abstract</b>
                            Empty</div>
                          <div id='notes9' class='bib notes'><b>Notes</b>
                           Talk at google on NNLMs</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry10' class='bib entry'>

                    <a href='http://msr-waypoint.com/en-us/um/people/gzweig/Pubs/NAACL2013Regularities.pdf' class='title'>Linguistic Regularities in Continuous Space Word Representations.</a>
                    <br><span class='author'>Mikolov, Tomas and Yih, Wen-tau and Zweig, Geoffrey.</span> <br>
                    <span class='year'>2013</span><br>
                    <div id='annotation10hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno10' class='bib annotation'>
                          <div id='abstract10' class='bib abstract'><b>Abstract</b>
                            Continuous space language models have recently demonstrated outstanding results across a variety of tasks. In this paper, we examine the vector-space word representations that are implicitly learned by the input-layer weights. We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a relation-specific vector offset. This allows vector-oriented reasoning based on the offsets between words. For example, the male/female relationship is automatically learned, and with the induced vector representations, “King - Man + Woman” results in a vector very close to “Queen.” We demonstrate that the word vectors capture syntactic regularities by means of syntactic analogy questions (provided with this paper), and are able to correctly answer almost 40% of the questions. We demonstrate that the word vectors capture semantic regularities by using the vector offset method to answer SemEval-2012 Task 2 questions. Remarkably, this method outperforms the best previous systems.</div>
                          <div id='notes10' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry11' class='bib entry'>

                    <a href='https://www.aclweb.org/anthology/W/W12/W12-2703.pdf' class='title'>Deep neural network language models</a>
                    <br><span class='author'>Arisoy, Ebru and Sainath, Tara N and Kingsbury, Brian and Ramabhadran, Bhuvana.</span> <br>
                    <span class='year'>2012</span><br>
                    <div id='annotation11hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno11' class='bib annotation'>
                          <div id='abstract11' class='bib abstract'><b>Abstract</b>
                            In recent years, neural network language models (NNLMs) have shown success in both peplexity and word error rate (WER) compared to conventional n-gram language models. Most NNLMs are trained with one hidden layer. Deep neural networks (DNNs) with more hidden layers have been shown to capture higher-level discriminative information about input features, and thus produce better networks. Motivated by the success of DNNs in acoustic modeling, we explore deep neural network language models (DNN LMs) in this paper. Results on a Wall Street Journal (WSJ) task demonstrate that DNN LMs offer improvements over a single hidden layer NNLM. Furthermore, our preliminary results are competitive with a model M language model, considered to be one of the current state-of-the-art techniques for language modeling.</div>
                          <div id='notes11' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry12' class='bib entry'>

                    <a href='http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf' class='title'>Recurrent neural network based language model.</a>
                    <br><span class='author'>Mikolov, Tomas and Karafi{\'a}t, Martin and Burget, Lukas and Cernock{\`y}, Jan and Khudanpur, Sanjeev.</span> <br>
                    <span class='year'>2010</span><br>
                    <div id='annotation12hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno12' class='bib annotation'>
                          <div id='abstract12' class='bib abstract'><b>Abstract</b>
                            A new recurrent neural network based language model (RNN LM) with applications to speech recognition is presented. Results indicate that it is possible to obtain around 50% reduction of perplexity by using mixture of several RNN LMs, compared to a state of the art backoff language model. Speech recognition experiments show around 18% reduction of word error rate on the Wall Street Journal task when comparing models trained on the same amount of data, and around 5% on the much harder NIST RT05 task, even when the backoff model is trained on much more data than the RNN LM. We provide ample empirical evidence to suggest that connectionist language models are superior to standard n-gram techniques, except their high computational (training) complexity</div>
                          <div id='notes12' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry13' class='bib entry'>

                    <a href='http://cs231n.github.io/neural-networks-3/' class='title'>learning neural networks</a>
                    <br><span class='author'>Andrej Karpathy.</span> <br>
                    <span class='year'>Empty</span><br>
                    <div id='annotation13hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno13' class='bib annotation'>
                          <div id='abstract13' class='bib abstract'><b>Abstract</b>
                            </div>
                          <div id='notes13' class='bib notes'><b>Notes</b>
                           Really good advice for debugging learning in DNNs</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry14' class='bib entry'>

                    <a href='http://research.microsoft.com/pubs/192769/tricks-2012.pdf' class='title'>Stochastic Gradient Descent Tricks</a>
                    <br><span class='author'>Leon Bottou.</span> <br>
                    <span class='year'>2012</span><br>
                    <div id='annotation14hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno14' class='bib annotation'>
                          <div id='abstract14' class='bib abstract'><b>Abstract</b>
                            Chapter 1 strongly advocates the stochastic back-propagation method to train neural networks. This is in fact an instance of a more general technique called stochastic gradient descent (SGD). This chapter provides background material, explains why SGD is a good learning algorithm when the training set is large, and provides useful recommendations.</div>
                          <div id='notes14' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry15' class='bib entry'>

                    <a href='ftp://tlp.limsi.fr/public/emnlp05.pdf' class='title'>Training neural network language models on very large corpora</a>
                    <br><span class='author'>Schwenk, Holger and Gauvain, Jean-Luc.</span> <br>
                    <span class='year'>2005</span><br>
                    <div id='annotation15hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno15' class='bib annotation'>
                          <div id='abstract15' class='bib abstract'><b>Abstract</b>
                            During the last years there has been growing interest in using neural networks for language modeling. In contrast to the well known back-off n-gram language models, the neural network approach attempts to overcome the data sparseness problem by performing the estimation in a continuous space. This type of language model was mostly used for tasks for which only a very limited amount of in-domain training data is available. In this paper we present new algorithms to train a neural network language model on very large text corpora. This makes possible the use of the approach in domains where several hundreds of millions words of texts are available. The neural network language model is evaluated in a state-ofthe-art real-time continuous speech recognizer for French Broadcast News. Word error reductions of 0.5% absolute are reported using only a very limited amount of additional processing time.</div>
                          <div id='notes15' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry16' class='bib entry'>

                    <a href='http://arxiv.org/abs/1411.2738' class='title'>word2vec Parameter Learning Explained</a>
                    <br><span class='author'>Xin Rong.</span> <br>
                    <span class='year'>2014</span><br>
                    <div id='annotation16hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno16' class='bib annotation'>
                          <div id='abstract16' class='bib abstract'><b>Abstract</b>
                            The word2vec model and application by Mikolov et al. have attracted a great amount of attention in recent two years. The vector representations of words learned by word2vec models have been shown to carry semantic meanings and are useful in various NLP tasks. As an increasing number of researchers would like to experiment with word2vec or similar techniques, I notice that there lacks a material that comprehensively explains the parameter learning process of word embedding models in details, thus preventing researchers that are non-experts in neural networks from understanding the working mechanism of such models. This note provides detailed derivations and explanations of the parameter update equations of the word2vec models, including the original continuous bag-of-word (CBOW) and skip-gram (SG) models, as well as advanced optimization techniques, including hierarchical softmax and negative sampling. Intuitive interpretations of the gradient equations are also provided alongside mathematical derivations. In the appendix, a review on the basics of neuron networks and backpropagation is provided. I also created an interactive demo, wevi, to facilitate the intuitive understanding of the model.</div>
                          <div id='notes16' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry17' class='bib entry'>

                    <a href='http://arxiv.org/abs/1402.3722' class='title'>word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding
method</a>
                    <br><span class='author'>Yoav Goldberg and
Omer Levy.</span> <br>
                    <span class='year'>2014</span><br>
                    <div id='annotation17hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno17' class='bib annotation'>
                          <div id='abstract17' class='bib abstract'><b>Abstract</b>
                            The word2vec software of Tomas Mikolov and colleagues (this https URL ) has gained a lot of traction lately, and provides state-of-the-art word embeddings. The learning models behind the software are described in two research papers. We found the description of the models in these papers to be somewhat cryptic and hard to follow. While the motivations and presentation may be obvious to the neural-networks language-modeling crowd, we had to struggle quite a bit to figure out the rationale behind the equations. This note is an attempt to explain equation (4) (negative sampling) in "Distributed Representations of Words and Phrases and their Compositionality" by Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado and Jeffrey Dean.</div>
                          <div id='notes17' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry18' class='bib entry'>

                    <a href='http://arxiv.org/abs/1601.01705' class='title'>Learning to Compose Neural Networks for Question Answering</a>
                    <br><span class='author'>Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan.</span> <br>
                    <span class='year'>2016</span><br>
                    <div id='annotation18hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno18' class='bib annotation'>
                          <div id='abstract18' class='bib abstract'><b>Abstract</b>
                            We describe a question answering model that applies to both images and structured knowledge bases. The model uses natural language strings to automatically assemble neural networks from a collection of composable modules. Parameters for these modules are learned jointly with network-assembly parameters via reinforcement learning, with only (world, question, answer) triples as supervision. Our approach, which we term a dynamic neural model network, achieves state-of-the-art results on benchmark datasets in both visual and structured domains.</div>
                          <div id='notes18' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry19' class='bib entry'>

                    <a href='https://levyomer.files.wordpress.com/2015/03/improving-distributional-similarity-tacl-2015.pdf' class='title'>Improving distributional similarity with lessons learned from word embeddings</a>
                    <br><span class='author'>Levy, Omer and Goldberg, Yoav and Dagan, Ido.</span> <br>
                    <span class='year'>2015</span><br>
                    <div id='annotation19hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno19' class='bib annotation'>
                          <div id='abstract19' class='bib abstract'><b>Abstract</b>
                            Recent trends suggest that neuralnetwork-inspired word embedding models outperform traditional count-based distributional models on word similarity and analogy detection tasks. We reveal that much of the performance gains of word embeddings are due to certain system design choices and hyperparameter optimizations, rather than the embedding algorithms themselves. Furthermore, we show that these modifications can be transferred to traditional distributional models, yielding similar gains. In contrast to prior reports, we observe mostly local or insignificant performance differences between the methods, with no global advantage to any single approach over the others.</div>
                          <div id='notes19' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry20' class='bib entry'>

                    <a href='http://arxiv.org/abs/1411.4166' class='title'>Retrofitting Word Vectors to Semantic Lexicons</a>
                    <br><span class='author'>Faruqui, Manaal and Dodge, Jesse and Jauhar, Sujay Kumar and Dyer, Chris and Hovy, Eduard and Smith, Noah A.</span> <br>
                    <span class='year'>2015</span><br>
                    <div id='annotation20hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno20' class='bib annotation'>
                          <div id='abstract20' class='bib abstract'><b>Abstract</b>
                            Vector space word representations are learned from distributional information of words in large corpora. Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database. This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed. Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models. Our refinement method outperforms prior techniques for incorporating semantic lexicons into the word vector training algorithms.</div>
                          <div id='notes20' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry21' class='bib entry'>

                    <a href='http://neuralnetworksanddeeplearning.com/chap3.html' class='title'>Improving the way neural networks learn</a>
                    <br><span class='author'>Michael Nielsen.</span> <br>
                    <span class='year'>2016</span><br>
                    <div id='annotation21hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno21' class='bib annotation'>
                          <div id='abstract21' class='bib abstract'><b>Abstract</b>
                            Empty</div>
                          <div id='notes21' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry22' class='bib entry'>

                    <a href='http://sebastianruder.com/optimizing-gradient-descent/index.html' class='title'>An overview of gradient descent optimization algorithms</a>
                    <br><span class='author'>Empty.</span> <br>
                    <span class='year'>2016</span><br>
                    <div id='annotation22hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno22' class='bib annotation'>
                          <div id='abstract22' class='bib abstract'><b>Abstract</b>
                            Empty</div>
                          <div id='notes22' class='bib notes'><b>Notes</b>
                           great visualization and intuitions behind the algorithms</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry23' class='bib entry'>

                    <a href='https://github.com/ebenolson/pydata2015' class='title'>Neural networks with theano and lasagne</a>
                    <br><span class='author'>Empty.</span> <br>
                    <span class='year'>2015</span><br>
                    <div id='annotation23hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno23' class='bib annotation'>
                          <div id='abstract23' class='bib abstract'><b>Abstract</b>
                            Empty</div>
                          <div id='notes23' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry24' class='bib entry'>

                    <a href='http://www.jmlr.org/proceedings/papers/v9/gutmann10a/gutmann10a.pdf' class='title'>Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</a>
                    <br><span class='author'>Gutmann, Michael and Hyv{\"a}rinen, Aapo.</span> <br>
                    <span class='year'>2010</span><br>
                    <div id='annotation24hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno24' class='bib annotation'>
                          <div id='abstract24' class='bib abstract'><b>Abstract</b>
                            We present a new estimation principle for parameterized statistical models. The idea is to perform nonlinear logistic regression to discriminate between the observed data and some artificially generated noise, using the model log-density function in the regression nonlinearity. We show that this leads to a consistent (convergent) estimator of the parameters, and analyze the asymptotic variance. In particular, the method is shown to directly work for unnormalized models, i.e. models where the density function does not integrate to one. The normalization constant can be estimated just like any other parameter. For a tractable ICA model, we compare the method with other estimation methods that can be used to learn unnormalized models, including score matching, contrastive divergence, and maximum-likelihood where the normalization constant is estimated with importance sampling. Simulations show that noise-contrastive estimation offers the best trade-off between computational and statistical efficiency. The method is then applied to the modeling of natural images: We show that the method can successfully estimate a large-scale two-layer model and a Markov random field.</div>
                          <div id='notes24' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry25' class='bib entry'>

                    <a href='http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf' class='title'>Simple statistical gradient-following algorithms for connectionist reinforcement learning</a>
                    <br><span class='author'>Williams, Ronald J.</span> <br>
                    <span class='year'>1992</span><br>
                    <div id='annotation25hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno25' class='bib annotation'>
                          <div id='abstract25' class='bib abstract'><b>Abstract</b>
                            This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units.  These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed.  Specific expamples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right.  Also given are results that show how such algorithms can be naturally integrated with backpropagation.  We close with a brief discussion of a number of additional issues surrounded the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to develop similar but potentially more powerful reinforcement learning algorithms.</div>
                          <div id='notes25' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry26' class='bib entry'>

                    <a href='http://arxiv.org/pdf/1502.03044v2.pdf' class='title'>Show, attend and tell: Neural image caption generation with visual attention</a>
                    <br><span class='author'>Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard and Bengio, Yoshua.</span> <br>
                    <span class='year'>2015</span><br>
                    <div id='annotation26hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno26' class='bib annotation'>
                          <div id='abstract26' class='bib abstract'><b>Abstract</b>
                            Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-theart performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO.</div>
                          <div id='notes26' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry27' class='bib entry'>

                    <a href='http://www.machinelearning.org/archive/icml2009/papers/119.pdf' class='title'>Curriculum learning</a>
                    <br><span class='author'>Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason.</span> <br>
                    <span class='year'>2009</span><br>
                    <div id='annotation27hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno27' class='bib annotation'>
                          <div id='abstract27' class='bib abstract'><b>Abstract</b>
                            Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them “curriculum learning”. In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).</div>
                          <div id='notes27' class='bib notes'><b>Notes</b>
                           This could be really useful if we use it to only learn substitutions at first</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry28' class='bib entry'>

                    <a href='https://docs.google.com/document/d/1IXF3h0RU5zz4ukmTrVKVotPQypChscNGf5k6E25HGvA/edit#' class='title'>Reading lists for new MILA students</a>
                    <br><span class='author'>Empty.</span> <br>
                    <span class='year'>Empty</span><br>
                    <div id='annotation28hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno28' class='bib annotation'>
                          <div id='abstract28' class='bib abstract'><b>Abstract</b>
                            Empty</div>
                          <div id='notes28' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry29' class='bib entry'>

                    <a href='http://www.cs.columbia.edu/~blei/seminar/2016_discrete_data/readings/BengioDucharmeVincentJanvin2003.pdf' class='title'>Neural probabilistic language models</a>
                    <br><span class='author'>Bengio, Yoshua and Schwenk, Holger and Sen{\'e}cal, Jean-S{\'e}bastien and Morin, Fr{\'e}deric and Gauvain, Jean-Luc.</span> <br>
                    <span class='year'>2006</span><br>
                    <div id='annotation29hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno29' class='bib annotation'>
                          <div id='abstract29' class='bib abstract'><b>Abstract</b>
                            A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the</div>
                          <div id='notes29' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry30' class='bib entry'>

                    <a href='https://www.cs.toronto.edu/~amnih/papers/hlbl_final.pdf' class='title'>A scalable hierarchical distributed language model</a>
                    <br><span class='author'>Mnih, Andriy and Hinton, Geoffrey E.</span> <br>
                    <span class='year'>2009</span><br>
                    <div id='annotation30hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno30' class='bib annotation'>
                          <div id='abstract30' class='bib abstract'><b>Abstract</b>
                            Neural probabilistic language models (NPLMs) have been shown to be competitive with and occasionally superior to the widely-used n-gram language models. The main drawback of NPLMs is their extremely long training and testing times. Morin and Bengio have proposed a hierarchical language model built around a binary tree of words, which was two orders of magnitude faster than the nonhierarchical model it was based on. However, it performed considerably worse than its non-hierarchical counterpart in spite of using a word tree created using expert knowledge. We introduce a fast hierarchical language model along with a simple feature-based algorithm for automatic construction of word trees from the data. We then show that the resulting models can outperform non-hierarchical neural models as well as the best n-gram models.</div>
                          <div id='notes30' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry31' class='bib entry'>

                    <a href='http://arxiv.org/abs/cs.CL/0108006' class='title'>Classes for Fast Maximum Entropy Training</a>
                    <br><span class='author'>Joshua Goodman.</span> <br>
                    <span class='year'>2001</span><br>
                    <div id='annotation31hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno31' class='bib annotation'>
                          <div id='abstract31' class='bib abstract'><b>Abstract</b>
                            Maximum entropy models are considered by many to be one of the most promising avenues of language modeling research. Unfortunately, long training times make maximum entropy research difficult. We present a novel speedup technique: we change the form of the model to use classes. Our speedup works by creating two maximum entropy models, the first of which predicts the class of each word, and the second of which predicts the word itself. This factoring of the model leads to fewer non-zero indicator functions, and faster normalization, achieving speedups of up to a factor of 35 over one of the best previous techniques. It also results in typically slightly lower perplexities. The same trick can be used to speed training of other machine learning techniques, e.g. neural networks, applied to any problem with a large number of outputs, such as language modeling.</div>
                          <div id='notes31' class='bib notes'><b>Notes</b>
                           not actual bib, get real bib when needs to be used</div>
                    </div>
                  </div>
                 </li>
                
<li>
                  <div id='entry32' class='bib entry'>

                    <a href='http://www.iro.umontreal.ca/~lisa/pointeurs/hierarchical-nnlm-aistats05.pdf' class='title'>Hierarchical Probabilistic Neural Network Language Model.</a>
                    <br><span class='author'>Morin, Frederic and Bengio, Yoshua.</span> <br>
                    <span class='year'>2005</span><br>
                    <div id='annotation32hider' class='bib no-selection btn'>hide annotations</div>
                    <div id='anno32' class='bib annotation'>
                          <div id='abstract32' class='bib abstract'><b>Abstract</b>
                            In recent years, variants of a neural network architecture for statistical language modeling have been proposed and successfully applied, e.g. in the language modeling component of speech recognizers. The main advantage of these architectures is that they learn an embedding for words (or other symbols) in a continuous space that helps to smooth the language model and provide good generalization even when the number of training examples is insufficient. However, these models are extremely slow in comparison to the more commonly used n-gram models, both for training and recognition. As an alternative to an importance sampling method proposed to speed-up training, we introduce a hierarchical decomposition of the conditional probabilities that yields a speed-up of about 200 both during training and recognition. The hierarchical decomposition is a binary hierarchical clustering constrained by the prior knowledge extracted from the WordNet semantic hierarchy.</div>
                          <div id='notes32' class='bib notes'><b>Notes</b>
                           Empty</div>
                    </div>
                  </div>
                 </li>
                
</ul></div>


<script>var options={valueNames:['title','author','year', 'abstract', 'notes']};
var userList = new List('bibitems', options);</script><script>
        var bibentry0on = true;
        $('#annotation0hider').click(function() {
            console.trace('here');
            if (bibentry0on) {
                $('#annotation0hider').html('show annotations');
                $('#anno0.bib.annotation').css('display', 'none');
                bibentry0on = false;
            }
            else {
                $('#anno0.bib.annotation').css('display', 'inherit');
                $('#annotation0hider').html("hide annotations");
                bibentry0on = true;
            }
        });
        $('#annotation0hider').click();</script>
<script>
        var bibentry1on = true;
        $('#annotation1hider').click(function() {
            console.trace('here');
            if (bibentry1on) {
                $('#annotation1hider').html('show annotations');
                $('#anno1.bib.annotation').css('display', 'none');
                bibentry1on = false;
            }
            else {
                $('#anno1.bib.annotation').css('display', 'inherit');
                $('#annotation1hider').html("hide annotations");
                bibentry1on = true;
            }
        });
        $('#annotation1hider').click();</script>
<script>
        var bibentry2on = true;
        $('#annotation2hider').click(function() {
            console.trace('here');
            if (bibentry2on) {
                $('#annotation2hider').html('show annotations');
                $('#anno2.bib.annotation').css('display', 'none');
                bibentry2on = false;
            }
            else {
                $('#anno2.bib.annotation').css('display', 'inherit');
                $('#annotation2hider').html("hide annotations");
                bibentry2on = true;
            }
        });
        $('#annotation2hider').click();</script>
<script>
        var bibentry3on = true;
        $('#annotation3hider').click(function() {
            console.trace('here');
            if (bibentry3on) {
                $('#annotation3hider').html('show annotations');
                $('#anno3.bib.annotation').css('display', 'none');
                bibentry3on = false;
            }
            else {
                $('#anno3.bib.annotation').css('display', 'inherit');
                $('#annotation3hider').html("hide annotations");
                bibentry3on = true;
            }
        });
        $('#annotation3hider').click();</script>
<script>
        var bibentry4on = true;
        $('#annotation4hider').click(function() {
            console.trace('here');
            if (bibentry4on) {
                $('#annotation4hider').html('show annotations');
                $('#anno4.bib.annotation').css('display', 'none');
                bibentry4on = false;
            }
            else {
                $('#anno4.bib.annotation').css('display', 'inherit');
                $('#annotation4hider').html("hide annotations");
                bibentry4on = true;
            }
        });
        $('#annotation4hider').click();</script>
<script>
        var bibentry5on = true;
        $('#annotation5hider').click(function() {
            console.trace('here');
            if (bibentry5on) {
                $('#annotation5hider').html('show annotations');
                $('#anno5.bib.annotation').css('display', 'none');
                bibentry5on = false;
            }
            else {
                $('#anno5.bib.annotation').css('display', 'inherit');
                $('#annotation5hider').html("hide annotations");
                bibentry5on = true;
            }
        });
        $('#annotation5hider').click();</script>
<script>
        var bibentry6on = true;
        $('#annotation6hider').click(function() {
            console.trace('here');
            if (bibentry6on) {
                $('#annotation6hider').html('show annotations');
                $('#anno6.bib.annotation').css('display', 'none');
                bibentry6on = false;
            }
            else {
                $('#anno6.bib.annotation').css('display', 'inherit');
                $('#annotation6hider').html("hide annotations");
                bibentry6on = true;
            }
        });
        $('#annotation6hider').click();</script>
<script>
        var bibentry7on = true;
        $('#annotation7hider').click(function() {
            console.trace('here');
            if (bibentry7on) {
                $('#annotation7hider').html('show annotations');
                $('#anno7.bib.annotation').css('display', 'none');
                bibentry7on = false;
            }
            else {
                $('#anno7.bib.annotation').css('display', 'inherit');
                $('#annotation7hider').html("hide annotations");
                bibentry7on = true;
            }
        });
        $('#annotation7hider').click();</script>
<script>
        var bibentry8on = true;
        $('#annotation8hider').click(function() {
            console.trace('here');
            if (bibentry8on) {
                $('#annotation8hider').html('show annotations');
                $('#anno8.bib.annotation').css('display', 'none');
                bibentry8on = false;
            }
            else {
                $('#anno8.bib.annotation').css('display', 'inherit');
                $('#annotation8hider').html("hide annotations");
                bibentry8on = true;
            }
        });
        $('#annotation8hider').click();</script>
<script>
        var bibentry9on = true;
        $('#annotation9hider').click(function() {
            console.trace('here');
            if (bibentry9on) {
                $('#annotation9hider').html('show annotations');
                $('#anno9.bib.annotation').css('display', 'none');
                bibentry9on = false;
            }
            else {
                $('#anno9.bib.annotation').css('display', 'inherit');
                $('#annotation9hider').html("hide annotations");
                bibentry9on = true;
            }
        });
        $('#annotation9hider').click();</script>
<script>
        var bibentry10on = true;
        $('#annotation10hider').click(function() {
            console.trace('here');
            if (bibentry10on) {
                $('#annotation10hider').html('show annotations');
                $('#anno10.bib.annotation').css('display', 'none');
                bibentry10on = false;
            }
            else {
                $('#anno10.bib.annotation').css('display', 'inherit');
                $('#annotation10hider').html("hide annotations");
                bibentry10on = true;
            }
        });
        $('#annotation10hider').click();</script>
<script>
        var bibentry11on = true;
        $('#annotation11hider').click(function() {
            console.trace('here');
            if (bibentry11on) {
                $('#annotation11hider').html('show annotations');
                $('#anno11.bib.annotation').css('display', 'none');
                bibentry11on = false;
            }
            else {
                $('#anno11.bib.annotation').css('display', 'inherit');
                $('#annotation11hider').html("hide annotations");
                bibentry11on = true;
            }
        });
        $('#annotation11hider').click();</script>
<script>
        var bibentry12on = true;
        $('#annotation12hider').click(function() {
            console.trace('here');
            if (bibentry12on) {
                $('#annotation12hider').html('show annotations');
                $('#anno12.bib.annotation').css('display', 'none');
                bibentry12on = false;
            }
            else {
                $('#anno12.bib.annotation').css('display', 'inherit');
                $('#annotation12hider').html("hide annotations");
                bibentry12on = true;
            }
        });
        $('#annotation12hider').click();</script>
<script>
        var bibentry13on = true;
        $('#annotation13hider').click(function() {
            console.trace('here');
            if (bibentry13on) {
                $('#annotation13hider').html('show annotations');
                $('#anno13.bib.annotation').css('display', 'none');
                bibentry13on = false;
            }
            else {
                $('#anno13.bib.annotation').css('display', 'inherit');
                $('#annotation13hider').html("hide annotations");
                bibentry13on = true;
            }
        });
        $('#annotation13hider').click();</script>
<script>
        var bibentry14on = true;
        $('#annotation14hider').click(function() {
            console.trace('here');
            if (bibentry14on) {
                $('#annotation14hider').html('show annotations');
                $('#anno14.bib.annotation').css('display', 'none');
                bibentry14on = false;
            }
            else {
                $('#anno14.bib.annotation').css('display', 'inherit');
                $('#annotation14hider').html("hide annotations");
                bibentry14on = true;
            }
        });
        $('#annotation14hider').click();</script>
<script>
        var bibentry15on = true;
        $('#annotation15hider').click(function() {
            console.trace('here');
            if (bibentry15on) {
                $('#annotation15hider').html('show annotations');
                $('#anno15.bib.annotation').css('display', 'none');
                bibentry15on = false;
            }
            else {
                $('#anno15.bib.annotation').css('display', 'inherit');
                $('#annotation15hider').html("hide annotations");
                bibentry15on = true;
            }
        });
        $('#annotation15hider').click();</script>
<script>
        var bibentry16on = true;
        $('#annotation16hider').click(function() {
            console.trace('here');
            if (bibentry16on) {
                $('#annotation16hider').html('show annotations');
                $('#anno16.bib.annotation').css('display', 'none');
                bibentry16on = false;
            }
            else {
                $('#anno16.bib.annotation').css('display', 'inherit');
                $('#annotation16hider').html("hide annotations");
                bibentry16on = true;
            }
        });
        $('#annotation16hider').click();</script>
<script>
        var bibentry17on = true;
        $('#annotation17hider').click(function() {
            console.trace('here');
            if (bibentry17on) {
                $('#annotation17hider').html('show annotations');
                $('#anno17.bib.annotation').css('display', 'none');
                bibentry17on = false;
            }
            else {
                $('#anno17.bib.annotation').css('display', 'inherit');
                $('#annotation17hider').html("hide annotations");
                bibentry17on = true;
            }
        });
        $('#annotation17hider').click();</script>
<script>
        var bibentry18on = true;
        $('#annotation18hider').click(function() {
            console.trace('here');
            if (bibentry18on) {
                $('#annotation18hider').html('show annotations');
                $('#anno18.bib.annotation').css('display', 'none');
                bibentry18on = false;
            }
            else {
                $('#anno18.bib.annotation').css('display', 'inherit');
                $('#annotation18hider').html("hide annotations");
                bibentry18on = true;
            }
        });
        $('#annotation18hider').click();</script>
<script>
        var bibentry19on = true;
        $('#annotation19hider').click(function() {
            console.trace('here');
            if (bibentry19on) {
                $('#annotation19hider').html('show annotations');
                $('#anno19.bib.annotation').css('display', 'none');
                bibentry19on = false;
            }
            else {
                $('#anno19.bib.annotation').css('display', 'inherit');
                $('#annotation19hider').html("hide annotations");
                bibentry19on = true;
            }
        });
        $('#annotation19hider').click();</script>
<script>
        var bibentry20on = true;
        $('#annotation20hider').click(function() {
            console.trace('here');
            if (bibentry20on) {
                $('#annotation20hider').html('show annotations');
                $('#anno20.bib.annotation').css('display', 'none');
                bibentry20on = false;
            }
            else {
                $('#anno20.bib.annotation').css('display', 'inherit');
                $('#annotation20hider').html("hide annotations");
                bibentry20on = true;
            }
        });
        $('#annotation20hider').click();</script>
<script>
        var bibentry21on = true;
        $('#annotation21hider').click(function() {
            console.trace('here');
            if (bibentry21on) {
                $('#annotation21hider').html('show annotations');
                $('#anno21.bib.annotation').css('display', 'none');
                bibentry21on = false;
            }
            else {
                $('#anno21.bib.annotation').css('display', 'inherit');
                $('#annotation21hider').html("hide annotations");
                bibentry21on = true;
            }
        });
        $('#annotation21hider').click();</script>
<script>
        var bibentry22on = true;
        $('#annotation22hider').click(function() {
            console.trace('here');
            if (bibentry22on) {
                $('#annotation22hider').html('show annotations');
                $('#anno22.bib.annotation').css('display', 'none');
                bibentry22on = false;
            }
            else {
                $('#anno22.bib.annotation').css('display', 'inherit');
                $('#annotation22hider').html("hide annotations");
                bibentry22on = true;
            }
        });
        $('#annotation22hider').click();</script>
<script>
        var bibentry23on = true;
        $('#annotation23hider').click(function() {
            console.trace('here');
            if (bibentry23on) {
                $('#annotation23hider').html('show annotations');
                $('#anno23.bib.annotation').css('display', 'none');
                bibentry23on = false;
            }
            else {
                $('#anno23.bib.annotation').css('display', 'inherit');
                $('#annotation23hider').html("hide annotations");
                bibentry23on = true;
            }
        });
        $('#annotation23hider').click();</script>
<script>
        var bibentry24on = true;
        $('#annotation24hider').click(function() {
            console.trace('here');
            if (bibentry24on) {
                $('#annotation24hider').html('show annotations');
                $('#anno24.bib.annotation').css('display', 'none');
                bibentry24on = false;
            }
            else {
                $('#anno24.bib.annotation').css('display', 'inherit');
                $('#annotation24hider').html("hide annotations");
                bibentry24on = true;
            }
        });
        $('#annotation24hider').click();</script>
<script>
        var bibentry25on = true;
        $('#annotation25hider').click(function() {
            console.trace('here');
            if (bibentry25on) {
                $('#annotation25hider').html('show annotations');
                $('#anno25.bib.annotation').css('display', 'none');
                bibentry25on = false;
            }
            else {
                $('#anno25.bib.annotation').css('display', 'inherit');
                $('#annotation25hider').html("hide annotations");
                bibentry25on = true;
            }
        });
        $('#annotation25hider').click();</script>
<script>
        var bibentry26on = true;
        $('#annotation26hider').click(function() {
            console.trace('here');
            if (bibentry26on) {
                $('#annotation26hider').html('show annotations');
                $('#anno26.bib.annotation').css('display', 'none');
                bibentry26on = false;
            }
            else {
                $('#anno26.bib.annotation').css('display', 'inherit');
                $('#annotation26hider').html("hide annotations");
                bibentry26on = true;
            }
        });
        $('#annotation26hider').click();</script>
<script>
        var bibentry27on = true;
        $('#annotation27hider').click(function() {
            console.trace('here');
            if (bibentry27on) {
                $('#annotation27hider').html('show annotations');
                $('#anno27.bib.annotation').css('display', 'none');
                bibentry27on = false;
            }
            else {
                $('#anno27.bib.annotation').css('display', 'inherit');
                $('#annotation27hider').html("hide annotations");
                bibentry27on = true;
            }
        });
        $('#annotation27hider').click();</script>
<script>
        var bibentry28on = true;
        $('#annotation28hider').click(function() {
            console.trace('here');
            if (bibentry28on) {
                $('#annotation28hider').html('show annotations');
                $('#anno28.bib.annotation').css('display', 'none');
                bibentry28on = false;
            }
            else {
                $('#anno28.bib.annotation').css('display', 'inherit');
                $('#annotation28hider').html("hide annotations");
                bibentry28on = true;
            }
        });
        $('#annotation28hider').click();</script>
<script>
        var bibentry29on = true;
        $('#annotation29hider').click(function() {
            console.trace('here');
            if (bibentry29on) {
                $('#annotation29hider').html('show annotations');
                $('#anno29.bib.annotation').css('display', 'none');
                bibentry29on = false;
            }
            else {
                $('#anno29.bib.annotation').css('display', 'inherit');
                $('#annotation29hider').html("hide annotations");
                bibentry29on = true;
            }
        });
        $('#annotation29hider').click();</script>
<script>
        var bibentry30on = true;
        $('#annotation30hider').click(function() {
            console.trace('here');
            if (bibentry30on) {
                $('#annotation30hider').html('show annotations');
                $('#anno30.bib.annotation').css('display', 'none');
                bibentry30on = false;
            }
            else {
                $('#anno30.bib.annotation').css('display', 'inherit');
                $('#annotation30hider').html("hide annotations");
                bibentry30on = true;
            }
        });
        $('#annotation30hider').click();</script>
<script>
        var bibentry31on = true;
        $('#annotation31hider').click(function() {
            console.trace('here');
            if (bibentry31on) {
                $('#annotation31hider').html('show annotations');
                $('#anno31.bib.annotation').css('display', 'none');
                bibentry31on = false;
            }
            else {
                $('#anno31.bib.annotation').css('display', 'inherit');
                $('#annotation31hider').html("hide annotations");
                bibentry31on = true;
            }
        });
        $('#annotation31hider').click();</script>
<script>
        var bibentry32on = true;
        $('#annotation32hider').click(function() {
            console.trace('here');
            if (bibentry32on) {
                $('#annotation32hider').html('show annotations');
                $('#anno32.bib.annotation').css('display', 'none');
                bibentry32on = false;
            }
            else {
                $('#anno32.bib.annotation').css('display', 'inherit');
                $('#annotation32hider').html("hide annotations");
                bibentry32on = true;
            }
        });
        $('#annotation32hider').click();</script>
<script> var allshowing=false; 
function hideall() { 
allshowing=false;bibentry0on = true; $('#annotation0hider').click();
bibentry1on = true; $('#annotation1hider').click();
bibentry2on = true; $('#annotation2hider').click();
bibentry3on = true; $('#annotation3hider').click();
bibentry4on = true; $('#annotation4hider').click();
bibentry5on = true; $('#annotation5hider').click();
bibentry6on = true; $('#annotation6hider').click();
bibentry7on = true; $('#annotation7hider').click();
bibentry8on = true; $('#annotation8hider').click();
bibentry9on = true; $('#annotation9hider').click();
bibentry10on = true; $('#annotation10hider').click();
bibentry11on = true; $('#annotation11hider').click();
bibentry12on = true; $('#annotation12hider').click();
bibentry13on = true; $('#annotation13hider').click();
bibentry14on = true; $('#annotation14hider').click();
bibentry15on = true; $('#annotation15hider').click();
bibentry16on = true; $('#annotation16hider').click();
bibentry17on = true; $('#annotation17hider').click();
bibentry18on = true; $('#annotation18hider').click();
bibentry19on = true; $('#annotation19hider').click();
bibentry20on = true; $('#annotation20hider').click();
bibentry21on = true; $('#annotation21hider').click();
bibentry22on = true; $('#annotation22hider').click();
bibentry23on = true; $('#annotation23hider').click();
bibentry24on = true; $('#annotation24hider').click();
bibentry25on = true; $('#annotation25hider').click();
bibentry26on = true; $('#annotation26hider').click();
bibentry27on = true; $('#annotation27hider').click();
bibentry28on = true; $('#annotation28hider').click();
bibentry29on = true; $('#annotation29hider').click();
bibentry30on = true; $('#annotation30hider').click();
bibentry31on = true; $('#annotation31hider').click();
bibentry32on = true; $('#annotation32hider').click();
}
function showall() { 
allshowing=true;
bibentry0on = false; $('#annotation0hider').click();
bibentry1on = false; $('#annotation1hider').click();
bibentry2on = false; $('#annotation2hider').click();
bibentry3on = false; $('#annotation3hider').click();
bibentry4on = false; $('#annotation4hider').click();
bibentry5on = false; $('#annotation5hider').click();
bibentry6on = false; $('#annotation6hider').click();
bibentry7on = false; $('#annotation7hider').click();
bibentry8on = false; $('#annotation8hider').click();
bibentry9on = false; $('#annotation9hider').click();
bibentry10on = false; $('#annotation10hider').click();
bibentry11on = false; $('#annotation11hider').click();
bibentry12on = false; $('#annotation12hider').click();
bibentry13on = false; $('#annotation13hider').click();
bibentry14on = false; $('#annotation14hider').click();
bibentry15on = false; $('#annotation15hider').click();
bibentry16on = false; $('#annotation16hider').click();
bibentry17on = false; $('#annotation17hider').click();
bibentry18on = false; $('#annotation18hider').click();
bibentry19on = false; $('#annotation19hider').click();
bibentry20on = false; $('#annotation20hider').click();
bibentry21on = false; $('#annotation21hider').click();
bibentry22on = false; $('#annotation22hider').click();
bibentry23on = false; $('#annotation23hider').click();
bibentry24on = false; $('#annotation24hider').click();
bibentry25on = false; $('#annotation25hider').click();
bibentry26on = false; $('#annotation26hider').click();
bibentry27on = false; $('#annotation27hider').click();
bibentry28on = false; $('#annotation28hider').click();
bibentry29on = false; $('#annotation29hider').click();
bibentry30on = false; $('#annotation30hider').click();
bibentry31on = false; $('#annotation31hider').click();
bibentry32on = false; $('#annotation32hider').click();
}
$('#showhide').click(function() {if (allshowing) { hideall(); $('#showhide').html('Expand all annoations');}else { showall(); $('#showhide').html('Hide all annoations');}});</script>
